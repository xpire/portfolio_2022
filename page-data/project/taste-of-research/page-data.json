{
    "componentChunkName": "component---src-templates-post-template-js",
    "path": "/project/taste-of-research/",
    "result": {"data":{"mdx":{"frontmatter":{"title":"Automatically detecting silences in speech","date":"May 10th, 2019","type":"Solo Project","stack":["Python","Jupyter-Notebook","Signal-Processing"],"code":"https://github.com/xpire/SilenceDetection","live":"https://github.com/xpire/SilenceDetection","image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","images":{"fallback":{"src":"/static/56cd2ba7701d90bce429e8ce45105199/e018d/tor.png","srcSet":"/static/56cd2ba7701d90bce429e8ce45105199/0c057/tor.png 750w,\n/static/56cd2ba7701d90bce429e8ce45105199/900d9/tor.png 1080w,\n/static/56cd2ba7701d90bce429e8ce45105199/35942/tor.png 1366w,\n/static/56cd2ba7701d90bce429e8ce45105199/e018d/tor.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/56cd2ba7701d90bce429e8ce45105199/f1c30/tor.webp 750w,\n/static/56cd2ba7701d90bce429e8ce45105199/54311/tor.webp 1080w,\n/static/56cd2ba7701d90bce429e8ce45105199/8d6ee/tor.webp 1366w,\n/static/56cd2ba7701d90bce429e8ce45105199/702da/tor.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625},"blurHash":{"base64Image":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAASCAYAAAA6yNxSAAAACXBIWXMAAAPoAAAD6AG1e1JrAAAE8UlEQVRIidWU2W7j2hVE9f8fdDvuwW63ZUvWPHGeR5EiKVLUQFKUtAKpbxIEuY8BghxgPVft2qd2h//x6/zfGrgCF6DlxpnrP2m5cuHKlRu3/5aBK3DmQsWZw62ivBwp2gPbc0nW7EjrgrT6TVYVbKsdeVWyq/bs6wPH+siprqibmqZpaM9nLuf2QeevBO/eW1qqW8PhcqI47x8i8SkjOGxwyzV2EWDmPvrWRcsctPQ3eupiph5W6uNmAX62JtzGxNsNSZ6SFhnbYku+yyl2BZ1HYLeWy+3M+dpQXyqO5yO7uiQ75cSHBH8XYef+Q0jaGCwjlVkoMw5Eht6Kgbt8MHSWjJwVE1dg5kosPQXR11B8Az2wMEMHe+3iRj5+FBDEIZ2mrajPJ6rzkWNzoLzHd8xJ9inhLsLZ+uiJjRjrzEOZkbei78zpWhN+GkOe9QE/tE9+qH1+qJ+8qANe1SFdbUxfnzI0FkxNgYUlIdoKsqOhuQa6Z2J4Fp2qOXLnWB/YVyXFqSA7ZES7DV4eYqYucmywCBVGnkDPnvHLHPOsDfiq9vib/M4fUpc/xC5fxC5P4gffpR4v8oA3ZURPnTLUF0wNgaUpIVoKsq2hOsbDSKdpa5pzTXU+cWyOlFXJ9pizKVOCIsLKfJSNxXKtMfZF+s6CN3PKsz7km/rJk9Lji/zBF+mDJ+mDb1KfZ3nAqzLiXZ0y0BdMjNWfCagojo7m/p7e9G0619uF6/VCe21pLg2nc/X4udvTjnif4RcxZhYgb2yWa51xIPPprujac17NKS/6PY3RgxdtzC9twrs+o28sGJkCM1tGcDRkz0D3bazAxV37+OuAIAr/vQWP33+9ULUN++bE9lQSH3L8XYK1DVESDyG2mIUaI19h4N0Tua9l9aBvrxjYImNHYu6qrDwdObDQQxf7LhqvWW9i4mRDkqakafafNbwfj/Z6pWrP7JuK7Wn/LxN5hJb6SBuHZWQyD3WmgcbEV5n6KjNfZeHrCIGBHFpoaxcr8vHiNWESE6cJaZaRb3OKvGCX7/76DlyuN+q25dDUFNWB5LAjLDPc/L6OEDXxkGIHIbJYhsZvAp1VYCAGJnJoo62dh7gbh4SbiDhJHhPnWc5uW1DmJfu8pPMY+R9c4dLeaM4tp7qhPB3ZHko2ZU5QJDhZhJH4qLGDFFkIfwovfe3BytMQfR3ZN9HuvQ9cnPC+75B1FLGJN2SblDzZUiQ5u7Sgc6mvXOoLbd3SVGeqU83hcGK335PtCuI8JchinCTAiF2UtYV4F/UU5q7E1BGZ2gJTS2BmCcwtkaUlP+qm2Bq6Y2K5Nq7r4ns+az8kDtZsgogkiOkcd0fuHIoDZVE+dpNlWzZp8ojufrXuF0z1DURXZWGLTM0lI2POQJvSV8f07n1XRvTlEQN5zEieMpFnzJUlK0VAUiUUTUHXNEzdwNZNHMPGNWw6203GnSxOSeKEOIoJwxAv8LA8G83RkSyFhSEw0ecM1Qk9eUBX7PNL+ODnqsvL8o2XxRs/52+8zru8zd95n/fozz8ZLoZMFhNmixnL5QJhuUJaCcgrEWUl0YmCNZG/fkQTeAGe62E7NoZtoJgqgi4yVxeM5Qmf0oB3ocfrssvz/JVvs2e+Tn7wNP7O0+jbg6/D73wfPvMy/Mnr8BfdUZfe6IPB6JPReMhkPGY2njCfTFlMZvwd9tFaBjOlRAsAAAAASUVORK5CYII=","hash":"TMQTS}?b}^~qj?S0=}R*Io~XR*WU"}}}},"slug":"taste-of-research/","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Automatically detecting silences in speech\",\n  \"slug\": \"tor\",\n  \"image\": \"./images/tor.png\",\n  \"date\": \"2019-05-10T00:00:00.000Z\",\n  \"author\": \"Justin\",\n  \"type\": \"Solo Project\",\n  \"stack\": [\"Python\", \"Jupyter-Notebook\", \"Signal-Processing\"],\n  \"code\": \"https://github.com/xpire/SilenceDetection\",\n  \"live\": \"https://github.com/xpire/SilenceDetection\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"In this project, I was tasked with cleaning hundreds of spoken\\nexcerpts of Dementia Patients' speech data.\"), mdx(\"p\", null, \"The structure of the recordings was a sequence of words spoken with\\nlarge gaps between each word, with the occasional remark from the\\ninterviewer. For such a seemingly simplistic problem, many existing\\nsilence detecting solutions I tried did not work. Hence, I decided to\\nbuild my own, and also explore how silence detection works.\"), mdx(\"p\", null, \"I used the python package \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"librosa\"), \" to conduct the audio\\nanalysis. Through my experimentations with this Jupyter Notebook, I\\nfixed DC offsets and used the RMS of the audio signal to calculate\\nwhen noise occured to detect the silences.\"));\n}\n;\nMDXContent.isMDXComponent = true;"}},"pageContext":{"slug":"taste-of-research/"}},
    "staticQueryHashes": ["2744905544","3935399047"]}